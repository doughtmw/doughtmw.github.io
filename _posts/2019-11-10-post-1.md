---
title: "HoloLens for Computer Vision in Unity"
date: 2019-11-10
permalink: /posts/HoloLensForCV-Unity-1
---

## Sample highlights
HoloLensForCV-Unity is a sample project which incorporates the [HoloLensForCV](https://github.com/microsoft/HoloLensForCV) sample from Microsoft into a C# project in Unity using [IL2CPP Windows Runtime Support](https://docs.unity3d.com/2018.4/Documentation/Manual/IL2CPP-WindowsRuntimeSupport.html). 

<img src="/images/HoloLens-PvDepth-Example.jpg" width="100">


## Windows Runtime Support in Unity
The project enables access to all [HoloLens research mode](https://docs.microsoft.com/en-us/windows/mixed-reality/research-mode) streams through Unity C# code using the HoloLensForCV [Windows Metadata file](https://docs.microsoft.com/en-us/uwp/winrt-cref/winmd-files). 

To enable Windows Runtime Support, the `ENABLE_WINMD_SUPPORT` #define directive is used to check that the project has runtime support enabled. Any call to a custom .winmd Windows API must be enclosed within this #define directive.

``` C#
// C# Unity 
// Enclose code within this #define directive
#if ENABLE_WINMD_SUPPORT

// WinMD file
using HoloLensForCV;

// Instance of Windows API class SensorFrameStreamer
private SensorFrameStreamer _sensorFrameStreamerPv;

#endif
```

Windows Runtime Support makes it far easier to integrate other libraries into Universal Windows Projects than it was using [dynamic linked libraries (DLLs)](https://docs.microsoft.com/en-us/cpp/porting/how-to-use-existing-cpp-code-in-a-universal-windows-platform-app?view=vs-2019). Microsoft has some [detailed documentation](https://docs.microsoft.com/en-us/windows/uwp/winrt-components/creating-windows-runtime-components-in-cpp) on implementing Windows Runtime components in C++. Below is a simple example.

## Runtime Support Example
### C++ sample 
In Visual Studio, create a new C++ WindowsRT component with:
``` C++
// .header file
// ref class definition
public ref class MyRuntimeClass sealed
{
public:
    // Constructor
    MyRuntimeClass();

    // Method to check if initialized
    bool IsClassInitialized();

private:
    bool _isRuntimeInitialized = false;
}
```
``` C++
// .cpp file
void MyRuntimeClass::MyRuntimeClass()
{
    _isRuntimeInitialized = true;
}

bool MyRuntimeClass::IsClassInitialized()
{
    return _isRuntimeInitialized;
};
```
Build the simple C++ sample and copy all output files to the Assets->Plugins->x86/x64 folder.

### Unity C# sample
It is now easy to access the above C++ WinRT component in Unity C# through IL2CPP build support. Open C# Unity scripts in Visual Studio, and be sure to select the .Player viewing option for code, otherwise `ENABLE_WINMD_SUPPORT` code in the #define directive with appear greyed out.

``` C#
// C# Unity
public class RuntimeSampleUnity
{
#if ENABLE_WINMD_SUPPORT
    private MyRuntimeClass _myRuntimeClass;
#endif

    // Default MonoBehaviour method
    void Start()
    {
#if ENABLE_WINMD_SUPPORT
        // New instance of runtime class
        _myRuntimeClass = new MyRuntimeClass();

        // Check to see if we initialized C++ runtime component
        var isInit = _myRuntimeClass.IsClassInitialized();
#endif

        Debug.LogFormat("MyRuntimeClass: {0}", isInit);
    }
}
```
Run the script in a Unity project. Hopefully the WinRT component is accessible through C# Unity.

## HoloLensForCV-Unity sample
As mentioned, this sample enables access to the HoloLens research mode streams, as well as OpenCV to enable real-time processing of sensor frames streamed from the Microsoft HoloLens device in a C# Unity environment using IL2CPP Windows Runtime Support. Here is a link to the project on my personal [Github repo](https://github.com/doughtmw/HoloLensForCV-Unity).

The included sample includes a Unity project which maps the short-throw time of flight (ToF) depth stream to the PV camera stream.

To map the depth frames to PV frames we require the following 4 x 4 transformation matrices:
- Depth camera: frame to origin transform (frameToOriginDepth)
- Depth camera: camera to view transform (cameraToViewDepth)
- PV camera: frame to origin transform (frameToOriginPV)
- PV camera: camera view transform (cameraToViewPV)
- PV camera: camera projection transform (cameraToProjectionPV)

The below [image](https://github.com/MicrosoftDocs/mixed-reality/blob/1e5d3036ce48120106af6cd8647c2aaaff21a881/mixed-reality-docs/locatable-camera.md) provides some more detail into how these camera transforms interact.

![sample](/images/camera-transforms.jpg)

The mapping follows a 2D -> 3D -> 3D -> 2D set of transformations, resulting in 2D fused depth-PV frames.

Compute inverse transforms to relate depth frames to PV frame coordinate mapping:
```
viewToCameraDepth = cameraToViewDepth^-1
originToFramePV = frameToOriginPV^-1
```

Depth to PV 4 x 4 transformation matrix and chain of transformations. We first map the 2D depth frames from the view to camera space, then from the depth frame to its origin. From the origin, we map to the PV camera frame, PV camera frame to view space, then from the PV view space to PV projection space.
```
depthToPV = viewToCameraDepth * frameToOriginDepth * originToFramePV * cameraToViewPV * cameraToProjectionPV
```

Compute the mapping of depth points and scale the 2D points by the final coordinate of the vector.
```
depthPvPoint = depthPoint * depthToPV
depthPvPoint = depthPvPoint / depthPvPoint[-1]
```

Now we scale the depth pv points to the size of the incoming camera frames.
```
xDepthPvPoint = pvFrameWidth * (depthPvPoint[0] + 1) / 2
yDepthPvPoint = pvFrameHeight * (1 - ((depthPvPoint[1].y + 1) / 2))
```
And finally can visualize the output on a canvas in Unity! The below image also contains some simple computer vision processing to display contours in depth PV frames using [OpenCV](https://opencv.org/) through the included [Nuget](https://docs.microsoft.com/en-us/nuget/what-is-nuget) package in my [Github repo](https://github.com/doughtmw/HoloLensForCV-Unity).

![sample](/images/HoloLens-PvDepth-Example.jpg)